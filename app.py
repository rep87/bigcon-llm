import json
import os
import re
import traceback
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

from app_core.failsoft import (
    compose_fail_soft_answer,
    external_adapter,
    rag_adapter,
    structured_adapter,
    weather_adapter,
)
from app_core.formatters import (
    get_age_bucket_details,
    merge_age_buckets,
    three_line_diagnosis,
    to_float_pct,
)

import pandas as pd
import streamlit as st

try:
    from rag import RetrievalTool
except Exception:  # pragma: no cover - optional dependency path
    RetrievalTool = None

# ===== í˜ì´ì§€ ê¸°ë³¸ =====
st.set_page_config(page_title="ì„±ë™êµ¬ ì†Œìƒê³µì¸ ë¹„ë°€ìƒë‹´ì‚¬ (MVP)", page_icon="ğŸ’¬", layout="wide")
st.title("ì„±ë™êµ¬ ì†Œìƒê³µì¸ ë¹„ë°€ìƒë‹´ì‚¬ (MVP)")
st.caption("Agent-1: ë°ì´í„° ì§‘ê³„/ìš”ì•½ â†’ Agent-2: ì‹¤í–‰ì¹´ë“œ(JSON) ìƒì„±")


def _env_flag(name: str, default: str) -> str:
    value = os.getenv(name)
    return value if value is not None else default


DEBUG_SHOW_RAW = _env_flag("DEBUG_SHOW_RAW", "true").lower() in {"1", "true", "yes"}


def _secret_value(name: str, default: str | None = None) -> str | None:
    try:
        return st.secrets.get(name, default)
    except Exception:  # pragma: no cover - Streamlit secrets unavailable
        return default


DEFAULT_RAG_ROOT = "data/rag"
RAG_ROOT = _secret_value("RAG_ROOT") or os.getenv("RAG_ROOT") or DEFAULT_RAG_ROOT
RAG_EMBED_VERSION = os.getenv("RAG_EMBED_VERSION", "embed_v1")
_DEFAULT_APP_MODE = (_secret_value("APP_MODE") or os.getenv("APP_MODE") or "public").lower()
if _DEFAULT_APP_MODE not in {"public", "debug"}:
    _DEFAULT_APP_MODE = "public"
if "_app_mode" not in st.session_state:
    st.session_state["_app_mode"] = _DEFAULT_APP_MODE
APP_MODE = st.session_state.get("_app_mode", "public")

if APP_MODE == "debug":
    show_debug = st.checkbox(
        "ğŸ” ë””ë²„ê·¸ ë³´ê¸°",
        value=st.session_state.get("show_debug_checkbox", True),
        key="show_debug_checkbox",
    )
else:
    show_debug = False
RAG_ROOT_PATH = Path(RAG_ROOT).expanduser()
RETRIEVAL_INIT_ERROR: str | None = None
RETRIEVAL_TOOL: object | None = None
RAG_CATALOG: list[Dict[str, Any]] = []
RAG_CATALOG_ERROR: str | None = None

if RetrievalTool is not None:
    try:
        RETRIEVAL_TOOL = RetrievalTool(root=RAG_ROOT, embed_version=RAG_EMBED_VERSION)
    except Exception as exc:  # pragma: no cover - defensive guard for UI
        RETRIEVAL_INIT_ERROR = str(exc)
else:  # pragma: no cover - module missing
    RETRIEVAL_INIT_ERROR = "rag.RetrievalTool ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

if RETRIEVAL_TOOL is not None and RETRIEVAL_INIT_ERROR is None:
    if not RAG_ROOT_PATH.exists():
        RAG_CATALOG_ERROR = f"RAG_ROOT ê²½ë¡œ({RAG_ROOT_PATH})ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    else:
        try:
            catalog_entries = RETRIEVAL_TOOL.load_catalog()
            for entry in catalog_entries:
                origin_path = entry.origin_path
                origin_uri = origin_path
                if origin_path:
                    path_obj = Path(origin_path)
                    if not path_obj.is_absolute():
                        origin_uri = (RAG_ROOT_PATH / path_obj).as_posix()
                    else:
                        origin_uri = path_obj.as_posix()
                RAG_CATALOG.append(
                    {
                        "document_id": entry.doc_id,
                        "title": entry.title,
                        "num_chunks": entry.num_chunks,
                        "embedding_model": entry.embedding_model,
                        "created_at": entry.created_at,
                        "origin_path": origin_uri,
                        "tags": list(entry.tags or []),
                        "year": entry.year,
                    }
                )
        except Exception as exc:  # pragma: no cover - defensive guard
            RAG_CATALOG_ERROR = str(exc)


def _get_debug_section(agent1_json: dict | None) -> dict:
    debug = (agent1_json or {}).get("debug")
    return debug if isinstance(debug, dict) else {}


if "_data_flags" not in st.session_state:
    st.session_state["_data_flags"] = {
        "use_weather": False,
        "use_external": False,
        "use_rag": True,
        "rag_threshold": 0.35,
        "rag_top_k": 5,
        "rag_mode": "auto",
        "rag_filter": "",
        "rag_selected_ids": [],
    }


def _get_debug_snapshot(agent1_json: dict | None) -> dict:
    debug = _get_debug_section(agent1_json)
    snap = debug.get("snapshot")
    if isinstance(snap, dict):
        sanitized = snap.get("sanitized")
        if isinstance(sanitized, dict):
            return sanitized
    legacy = debug.get("sanitized_snapshot")
    return legacy if isinstance(legacy, dict) else {}


def _compute_rag_info(question_text: str, flags_snapshot: Dict[str, Any]) -> Dict[str, Any]:
    selected_docs = [
        str(doc_id)
        for doc_id in (flags_snapshot.get("rag_selected_ids") or [])
        if str(doc_id)
    ]
    rag_requested = bool(flags_snapshot.get("use_rag", False))
    rag_mode = str(flags_snapshot.get("rag_mode", "auto"))
    rag_threshold = float(flags_snapshot.get("rag_threshold", 0.35))
    rag_top_k = int(flags_snapshot.get("rag_top_k", 5))
    return rag_adapter(
        question_text,
        RETRIEVAL_TOOL,
        enabled=rag_requested and bool(selected_docs),
        top_k=rag_top_k,
        threshold=rag_threshold,
        mode=rag_mode,
        requested=rag_requested,
        doc_ids=selected_docs,
    )


def _prepare_rag_prompt_context(rag_info: Dict[str, Any] | None) -> Dict[str, Any] | None:
    if not isinstance(rag_info, dict):
        return None
    payload = rag_info.get("payload") or {}
    chunks = payload.get("chunks") or []
    evidence = payload.get("evidence") or []
    context = {
        "enabled": bool(rag_info.get("enabled")),
        "requested": bool(rag_info.get("requested")),
        "selection_missing": bool(rag_info.get("selection_missing")),
        "selected_doc_ids": list(rag_info.get("selected_doc_ids") or []),
        "threshold": rag_info.get("threshold"),
        "mode": rag_info.get("mode"),
        "max_score": rag_info.get("max_score"),
        "hits": len(chunks),
        "chunks": [dict(chunk) for chunk in chunks],
        "evidence": [dict(item) for item in evidence],
        "error": rag_info.get("error"),
        "catalog_size": rag_info.get("catalog_size"),
        "top_scores": list(payload.get("top_scores") or []),
    }
    return context


def _shorten_snippet(text: Any, limit: int = 140) -> str:
    snippet = str(text or "").strip()
    if len(snippet) > limit:
        snippet = snippet[:limit].rstrip() + "â€¦"
    return snippet


def _format_evidence_line(entry: Dict[str, Any]) -> str:
    source = str(entry.get("source") or "NONE").upper()
    key = entry.get("key") or "â€”"
    value = entry.get("value")
    if value is None:
        value_text = "â€”"
    else:
        value_text = str(value)
    period = entry.get("period")
    snippet = entry.get("snippet")
    parts = [f"[{source}] {key}: {value_text}"]
    if period:
        parts.append(f"({period})")
    line = " ".join(parts)
    if snippet:
        line += f" â€” {_shorten_snippet(snippet)}"
    return f"- {line}"


def _iter_debug_distribution(data: Any) -> List[Tuple[str, Any]]:
    entries: List[Tuple[str, Any]] = []
    if isinstance(data, dict):
        for key, value in data.items():
            entries.append((str(key), value))
    elif isinstance(data, Sequence):
        for item in data:
            if not isinstance(item, dict):
                continue
            code = item.get("code") or item.get("key") or item.get("id") or item.get("label")
            if code is None:
                continue
            value = item.get("value")
            if value is None:
                for alt in ("percent", "ratio", "pct", "share"):
                    if alt in item:
                        value = item[alt]
                        break
            entries.append((str(code), value))
    return entries


_DEBUG_F_KEYS = ["F", "f", "FME", "female", "ì—¬", "ì—¬ì„±"]
_DEBUG_M_KEYS = ["M", "m", "MAL", "male", "ë‚¨", "ë‚¨ì„±"]


def _format_debug_pct(value: Any) -> str:
    pct, hint = to_float_pct(value)
    if pct is None:
        return f"{value!r} ({hint})"
    return f"{pct:.1f}% ({hint})"


def _lookup_gender_value(mapping: Dict[str, Any], aliases: Sequence[str]) -> Any:
    for alias in aliases:
        if alias in mapping:
            return mapping.get(alias)
    return None


def _build_debug_report_markdown(
    agent1_json: dict | None,
    *,
    question_type: str | None,
    rag_info: Dict[str, Any] | None,
    rag_prompt_context: Dict[str, Any] | None,
    prompt_trace: Dict[str, Any] | None,
    response_trace: Dict[str, Any] | None,
) -> str:
    if not isinstance(agent1_json, dict):
        return ""

    kpis = (agent1_json.get("kpis") or {}) if isinstance(agent1_json, dict) else {}
    sanitized_snapshot = _get_debug_snapshot(agent1_json)
    debug_section = _get_debug_section(agent1_json)
    raw_snapshot = ((debug_section.get("snapshot") or {}).get("raw") or {}) if isinstance(debug_section, dict) else {}

    lines: List[str] = ["### Debug Report"]
    lines.append("**Agent-1 Snapshot**")

    age_entries = _iter_debug_distribution(
        sanitized_snapshot.get("age_distribution") or kpis.get("age_distribution")
    )
    if age_entries:
        lines.append("- age_distribution:")
        for key, raw_value in age_entries:
            lines.append(f"    - {key}: {_format_debug_pct(raw_value)}")
    else:
        lines.append("- age_distribution: ì—†ìŒ")

    gender_data = (
        sanitized_snapshot.get("age_by_gender")
        or sanitized_snapshot.get("age_gender")
        or kpis.get("age_by_gender")
        or kpis.get("age_gender")
        or {}
    )
    if isinstance(gender_data, dict) and gender_data:
        lines.append("- age_by_gender:")
        for bucket, mapping in gender_data.items():
            if not isinstance(mapping, dict):
                continue
            female_raw = _lookup_gender_value(mapping, _DEBUG_F_KEYS)
            male_raw = _lookup_gender_value(mapping, _DEBUG_M_KEYS)
            lines.append(
                "    - "
                + f"{bucket}: F {_format_debug_pct(female_raw)}, M {_format_debug_pct(male_raw)}"
            )
    elif raw_snapshot:
        raw_keys = [key for key in raw_snapshot.keys() if "M12_" in str(key)]
        if raw_keys:
            lines.append(f"- raw age keys detected: {', '.join(raw_keys[:6])}")

    mix_detail = sanitized_snapshot.get("customer_mix_detail") or kpis.get("customer_mix_detail")
    if isinstance(mix_detail, dict) and mix_detail:
        lines.append("- customer_mix_detail:")
        for key, value in mix_detail.items():
            lines.append(f"    - {key}: {_format_debug_pct(value)}")

    new_raw = sanitized_snapshot.get("new_pct") or kpis.get("new_rate_avg")
    revisit_raw = sanitized_snapshot.get("revisit_pct") or kpis.get("revisit_rate_avg")
    lines.append(f"- ì‹ ê·œ ë¹„ì¤‘: {_format_debug_pct(new_raw)}")
    lines.append(f"- ì¬ë°©ë¬¸ ë¹„ì¤‘: {_format_debug_pct(revisit_raw)}")

    normalization_notes = [
        f"{key}={value}"
        for key, value in sanitized_snapshot.items()
        if isinstance(key, str) and "normalize" in key.lower()
    ]
    if normalization_notes:
        lines.append("- normalization flags:")
        for note in normalization_notes:
            lines.append(f"    - {note}")

    lines.append("\n**Age Merge Decision**")
    age_details = get_age_bucket_details(agent1_json or {})
    if age_details:
        for item in age_details:
            final_val = item.get("final_value")
            final_text = f"{final_val:.1f}%" if isinstance(final_val, (int, float)) else "â€”"
            status = "included" if item.get("included") else "skipped"
            lines.append(
                f"- {item.get('label')} ({item.get('key')}): {final_text} â† {item.get('source')} ({status})"
            )
            if item.get("notes"):
                lines.append(f"    - {item['notes']}")
    else:
        lines.append("- no age buckets detected")

    prompt_trace = prompt_trace or {}
    lines.append("\n**Agent-2 Prompt**")
    lines.append(f"- question_type: {question_type or prompt_trace.get('question_type')}")
    lines.append(f"- organizer_mode: {prompt_trace.get('organizer_mode')}")
    lines.append(f"- schema_keys: {prompt_trace.get('schema_keys')}")
    lines.append(
        f"- rag_context_included: {prompt_trace.get('rag_included')}"
        + (f" (reason: {prompt_trace.get('rag_reason')})" if prompt_trace.get("rag_reason") else "")
    )
    if prompt_trace.get("rag_context_doc_ids"):
        lines.append(f"- rag doc_ids: {prompt_trace.get('rag_context_doc_ids')}")

    response_trace = response_trace or {}
    lines.append("\n**Agent-2 Response Trace**")
    if not response_trace:
        lines.append("- response trace unavailable")
    else:
        status = response_trace.get("status")
        lines.append(f"- status: {status}")
        if response_trace.get("generation_config"):
            lines.append(f"- generation_config: {response_trace.get('generation_config')}")
        if response_trace.get("prompt_length") is not None:
            lines.append(f"- prompt_length: {response_trace.get('prompt_length')}")
        if response_trace.get("chosen_model"):
            lines.append(f"- chosen_model: {response_trace.get('chosen_model')}")
        if response_trace.get("last_error"):
            lines.append(f"- last_error: {response_trace.get('last_error')}")
        if response_trace.get("fallback_answers") is not None:
            lines.append(f"- fallback_answers: {response_trace.get('fallback_answers')}")
        attempts = response_trace.get("attempts") or []
        if attempts:
            lines.append("- attempts:")
            for attempt in attempts:
                label = f"attempt {attempt.get('attempt')} / {attempt.get('model')}"
                lines.append(f"    - {label}: {attempt.get('status')}")
                parse_logs = attempt.get("parse_logs") or []
                excerpt = ""
                for entry in parse_logs:
                    if not entry.get("success") and entry.get("excerpt"):
                        excerpt = entry["excerpt"].replace('\n', ' ')[:160]
                        break
                if excerpt:
                    lines.append(f"        Â· excerpt: {excerpt}")
                if attempt.get("raw_preview"):
                    preview = attempt.get("raw_preview").replace('\n', ' ')
                    lines.append(f"        Â· raw_preview: {preview[:160]}")
                if attempt.get("repair_logs"):
                    rep_logs = attempt["repair_logs"]
                    for entry in rep_logs:
                        if not entry.get("success") and entry.get("excerpt"):
                            snippet = entry["excerpt"].replace('\n', ' ')[:160]
                            lines.append(f"        Â· repair excerpt: {snippet}")
                            break

    rag_info = rag_info or {}
    lines.append("\n**RAG Retrieval**")
    if not rag_info:
        lines.append("- RAG info unavailable")
    else:
        lines.append(
            f"- requested={rag_info.get('requested')} enabled={rag_info.get('enabled')} selection_missing={rag_info.get('selection_missing')}"
        )
        lines.append(
            f"- selected_doc_ids: {rag_info.get('selected_doc_ids')} catalog_size={rag_info.get('catalog_size')}"
        )
        lines.append(
            f"- mode={rag_info.get('mode')} threshold={rag_info.get('threshold')} top_k={rag_info.get('top_k')}"
        )
        lines.append(
            f"- max_score={rag_info.get('max_score')} include_evidence={rag_info.get('include_evidence')} error={rag_info.get('error')}"
        )
        payload = rag_info.get("payload") or {}
        top_scores = rag_prompt_context.get("top_scores") if isinstance(rag_prompt_context, dict) else []
        if not top_scores:
            top_scores = payload.get("top_scores") or []
        if top_scores:
            rounded = [round(float(score), 3) for score in top_scores[:5]]
            lines.append(f"- top_scores: {rounded}")
        if not rag_info.get("include_evidence"):
            reason = ""
            max_score = rag_info.get("max_score")
            threshold = rag_info.get("threshold")
            if rag_info.get("error"):
                reason = rag_info.get("error")
            elif max_score is None:
                reason = "no hits"
            elif threshold is not None and max_score < threshold:
                reason = f"max_score {max_score:.3f} < threshold {threshold:.2f}"
            else:
                reason = "evidence suppressed"
            lines.append(f"- evidence omitted reason: {reason}")

    return "\n".join(lines)


def _match_evidence_chunk(
    entry: Dict[str, Any],
    retrieval_payload: Dict[str, Any] | None,
) -> tuple[Dict[str, Any] | None, Dict[str, Any] | None]:
    if not isinstance(entry, dict) or not retrieval_payload:
        return None, None
    doc_id = entry.get("doc_id")
    if not doc_id:
        return None, None
    chunk_id = entry.get("chunk_id")
    chunks = retrieval_payload.get("chunks") or []
    evidence_list = retrieval_payload.get("evidence") or []
    target_chunk = None
    target_meta = None
    chunk_id_str = str(chunk_id) if chunk_id is not None else None

    for chunk in chunks:
        if str(chunk.get("doc_id")) != str(doc_id):
            continue
        current_chunk_id = chunk.get("chunk_id")
        if chunk_id_str is not None and str(current_chunk_id) != chunk_id_str:
            continue
        target_chunk = chunk
        break

    if target_chunk is None:
        for chunk in chunks:
            if str(chunk.get("doc_id")) == str(doc_id):
                target_chunk = chunk
                break

    if target_chunk is not None:
        for meta in evidence_list:
            if str(meta.get("doc_id")) != str(doc_id):
                continue
            if chunk_id_str is not None:
                if str(meta.get("chunk_id")) == chunk_id_str:
                    target_meta = meta
                    break
            else:
                target_meta = meta
                break

    return target_chunk, target_meta


def _get_debug_raw_snapshot(agent1_json: dict | None) -> dict:
    debug = _get_debug_section(agent1_json)
    snap = debug.get("snapshot")
    if isinstance(snap, dict):
        raw = snap.get("raw")
        if isinstance(raw, dict):
            return raw
    legacy = debug.get("latest_raw_snapshot")
    return legacy if isinstance(legacy, dict) else {}


def _render_main_views(
    question_text: str,
    agent1_payload: dict | None,
    agent2_payload: dict | None,
    *,
    rag_info_override: Dict[str, Any] | None = None,
) -> None:
    flags_snapshot = st.session_state.get("_data_flags", {}).copy()
    structured_payload = structured_adapter(agent1_payload)
    weather_payload = weather_adapter(question_text, enabled=flags_snapshot.get("use_weather", False))
    external_payload = external_adapter(question_text, enabled=flags_snapshot.get("use_external", False))
    if rag_info_override is not None:
        rag_info = rag_info_override
    else:
        rag_info = _compute_rag_info(question_text, flags_snapshot)

    retrieval_payload = rag_info.get("payload") if isinstance(rag_info, dict) else None
    if rag_info.get("error"):
        st.warning(f"RetrievalTool ì˜¤ë¥˜: {rag_info['error']}")
    if retrieval_payload is not None:
        st.session_state['_latest_retrieval'] = retrieval_payload
    else:
        st.session_state['_latest_retrieval'] = None
    st.session_state['_latest_rag_info'] = rag_info
    st.session_state['_latest_rag_prompt_context'] = _prepare_rag_prompt_context(rag_info)

    fail_soft_payload = compose_fail_soft_answer(
        question_text,
        structured_payload,
        weather_payload,
        external_payload,
        rag_info,
        flags_snapshot,
    )
    st.session_state['_latest_failsoft'] = fail_soft_payload

    try:
        overview_cached = st.session_state.get('_latest_overview', (None, None))
        if isinstance(agent2_payload, dict):
            if retrieval_payload:
                agent2_payload.setdefault("evidence", retrieval_payload.get("evidence", []))
                agent2_payload.setdefault("retrieval_chunks", retrieval_payload.get("chunks", []))
            agent2_payload.setdefault("used_data", fail_soft_payload.get("used_data"))
            if APP_MODE == "debug":
                agent2_payload.setdefault("caveats", fail_soft_payload.get("caveats"))

        if APP_MODE == "debug" and show_debug:
            render_fail_soft_answer(fail_soft_payload, rag_info=rag_info)
        render_summary_view(
            agent1_payload,
            agent2_payload or {},
            overview_df=overview_cached[0],
            table_dict=overview_cached[1],
            retrieval_payload=retrieval_payload,
        )
    except Exception:
        st.error("ìš”ì•½ ë·°ë¥¼ ë Œë”ë§í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.code(traceback.format_exc())

def render_debug_view(agent1_json: dict | None, show_raw: bool = DEBUG_SHOW_RAW) -> None:
    debug = _get_debug_section(agent1_json)
    if not debug:
        st.info("ë””ë²„ê·¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    question_type = st.session_state.get("_latest_question_type")
    rag_info_state = st.session_state.get("_latest_rag_info")
    rag_prompt_state = st.session_state.get("_latest_rag_prompt_context")
    prompt_trace = st.session_state.get("_latest_prompt_trace")
    response_trace = st.session_state.get("_latest_response_trace")
    report_markdown = _build_debug_report_markdown(
        agent1_json,
        question_type=question_type,
        rag_info=rag_info_state,
        rag_prompt_context=rag_prompt_state,
        prompt_trace=prompt_trace,
        response_trace=response_trace,
    )
    if report_markdown:
        st.markdown(report_markdown)

    def _flatten_rows(obj: dict) -> pd.DataFrame:
        rows = []
        for key, value in (obj or {}).items():
            if isinstance(value, (dict, list)):
                try:
                    text = json.dumps(value, ensure_ascii=False)
                except TypeError:
                    text = str(value)
                rows.append({"í•­ëª©": key, "ê°’": text})
            else:
                rows.append({"í•­ëª©": key, "ê°’": value})
        return pd.DataFrame(rows)

    def _numeric_values(data):
        if isinstance(data, dict):
            for val in data.values():
                yield from _numeric_values(val)
        elif isinstance(data, (list, tuple)):
            for item in data:
                yield from _numeric_values(item)
        elif isinstance(data, (int, float)):
            yield data

    errors = debug.get("errors", [])
    resolve_info = debug.get("resolve", {}) or {}
    panel_info = debug.get("panel", {}) or {}
    snapshot_info = (debug.get("snapshot", {}) or {})
    sanitized_snapshot = snapshot_info.get("sanitized") or {}
    agent1_llm = debug.get("agent1_llm", {}) or {}

    warnings = []
    if resolve_info.get("resolved_merchant_id") is None:
        warnings.append("ê°€ë§¹ì  ë¯¸í™•ì •: ì „í‘œë³¸ ìš”ì•½ìœ¼ë¡œ ë–¨ì–´ì§ˆ ìœ„í—˜")
    rows_after = panel_info.get("rows_after")
    if rows_after is not None and rows_after != 1:
        warnings.append("ë‹¨ì¼ ìƒì  íŒ¨ë„ ì•„ë‹˜")
    for num in _numeric_values(sanitized_snapshot):
        try:
            val = float(num)
        except (TypeError, ValueError):
            continue
        if val < 0 or val > 100:
            warnings.append("ì •ê·œí™” ì‹¤íŒ¨ ì˜ì‹¬")
            break
    if agent1_llm.get("safety_blocked"):
        warnings.append("LLM ì•ˆì „ì„± ì°¨ë‹¨")

    for err in errors:
        stage = err.get('stage', 'unknown')
        msg = err.get('msg', '')
        st.error(f"[{stage}] {msg}")
    for warn in warnings:
        st.error(warn)

    input_info = debug.get("input", {}) or {}
    st.markdown("#### ì…ë ¥/í”Œë˜ê·¸")
    st.write("ì›ë¬¸:", input_info.get("original") or "â€”")
    flags = input_info.get("flags") or {}
    if flags:
        st.write({k: flags.get(k) for k in sorted(flags)})

    parse_info = debug.get("parse", {}) or {}
    st.markdown("#### íŒŒì‹± ê²°ê³¼")
    st.write({
        "merchant_mask": parse_info.get("merchant_mask"),
        "mask_prefix": parse_info.get("mask_prefix"),
        "sigungu": parse_info.get("sigungu"),
        "pattern_used": parse_info.get("pattern_used"),
        "elapsed_ms": parse_info.get("elapsed_ms"),
    })

    st.markdown("#### ê°€ë§¹ì  ë§¤ì¹­")
    st.write({
        "path": resolve_info.get("path"),
        "resolved_merchant_id": resolve_info.get("resolved_merchant_id"),
        "elapsed_ms": resolve_info.get("elapsed_ms"),
    })
    candidates = resolve_info.get("candidates_top3") or []
    if candidates:
        st.table(pd.DataFrame(candidates))
    else:
        st.write("í›„ë³´ ì—†ìŒ")

    st.markdown("#### íŒ¨ë„ í•„í„°")
    st.write({
        "rows_before": panel_info.get("rows_before"),
        "rows_after": panel_info.get("rows_after"),
        "latest_ta_ym": panel_info.get("latest_ta_ym"),
        "elapsed_ms": panel_info.get("elapsed_ms"),
    })

    st.markdown("#### ìŠ¤ëƒ…ìƒ·")
    if show_raw:
        raw_df = _flatten_rows(snapshot_info.get("raw") or {})
        if not raw_df.empty:
            st.caption("ì›ë³¸(raw)")
            st.table(raw_df)
    sanitized_df = _flatten_rows(sanitized_snapshot)
    if not sanitized_df.empty:
        st.caption("ì •ê·œí™”(sanitized)")
        st.table(sanitized_df)
    age_details = get_age_bucket_details(agent1_json or {})
    if age_details:
        st.caption("ì—°ë ¹ ë¶„í¬ ê²°ì •")
        st.table(pd.DataFrame(age_details))

    render_info = debug.get("render", {}) or {}
    table_dict = render_info.get("table_dict")
    if isinstance(table_dict, dict) and table_dict:
        st.markdown("#### ë Œë” í…Œì´ë¸”")
        st.table(pd.DataFrame([table_dict]))

    rag_info_state = st.session_state.get("_latest_rag_info")
    rag_prompt_state = st.session_state.get("_latest_rag_prompt_context") or {}
    st.markdown("#### RAG ìƒíƒœ")
    if isinstance(rag_info_state, dict):
        summary = {
            "requested": rag_info_state.get("requested"),
            "enabled": rag_info_state.get("enabled"),
            "selected_doc_ids": rag_info_state.get("selected_doc_ids"),
            "threshold": rag_info_state.get("threshold"),
            "max_score": rag_info_state.get("max_score"),
            "mode": rag_info_state.get("mode"),
            "error": rag_info_state.get("error"),
        }
        st.write(summary)
        payload = rag_info_state.get("payload") or {}
        chunk_rows = []
        for chunk in (payload.get("chunks") or [])[:5]:
            chunk_rows.append(
                {
                    "doc_id": chunk.get("doc_id"),
                    "chunk_id": chunk.get("chunk_id"),
                    "score": chunk.get("score"),
                }
            )
        if chunk_rows:
            st.table(pd.DataFrame(chunk_rows))
        else:
            st.write("ê·¼ê±° ì—†ìŒ ë˜ëŠ” ì„ê³„ê°’ ë¯¸ë‹¬")
        prompt_note = rag_prompt_state.get("prompt_note")
        if prompt_note:
            st.caption(_shorten_snippet(prompt_note, limit=200))
    else:
        st.write("RAG ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("#### Agent-1 LLM")
    st.write({
        "used": agent1_llm.get("used"),
        "model": agent1_llm.get("model"),
        "resp_bytes": agent1_llm.get("resp_bytes"),
        "safety_blocked": agent1_llm.get("safety_blocked"),
        "elapsed_ms": agent1_llm.get("elapsed_ms"),
    })
    preview = agent1_llm.get("prompt_preview")
    if preview:
        st.caption("í”„ë¡¬í”„íŠ¸ í”„ë¦¬ë·°")
        st.code(preview)


def _render_sources_footer(used_data: Dict[str, Any]) -> None:
    if not used_data:
        return

    st.caption("Sources Used")
    cols = st.columns(4)
    structured_text = "âœ… Structured" if used_data.get("structured") else "âšªï¸ Structured"
    weather_text = "âœ… Weather" if used_data.get("weather") else "âšªï¸ Weather"
    external_text = "âœ… External" if used_data.get("external") else "âšªï¸ External"
    rag_info = used_data.get("rag") or {}
    rag_enabled = bool(rag_info.get("enabled"))
    rag_hits = rag_info.get("hits") or 0
    rag_label = "âœ… RAG" if rag_enabled and rag_hits else ("âšªï¸ RAG" if rag_enabled else "ğŸš« RAG")
    rag_details = []
    if rag_hits:
        rag_details.append(f"hits={rag_hits}")
    max_score = rag_info.get("max_score")
    if isinstance(max_score, (int, float)):
        rag_details.append(f"max={max_score:.2f}")
    threshold = rag_info.get("threshold")
    if isinstance(threshold, (int, float)):
        rag_details.append(f"Î¸={threshold:.2f}")
    mode = rag_info.get("mode")
    if mode:
        rag_details.append(str(mode))
    selected_docs = rag_info.get("selected_docs") or []
    if selected_docs:
        rag_details.append(f"docs={len(selected_docs)}")
    elif rag_info.get("requested") and not rag_enabled:
        rag_details.append("docs=0")
    rag_text = rag_label + (" (" + ", ".join(rag_details) + ")" if rag_details else "")

    cols[0].markdown(structured_text)
    cols[1].markdown(weather_text)
    cols[2].markdown(external_text)
    cols[3].markdown(rag_text)


def render_fail_soft_answer(
    payload: Optional[Dict[str, Any]],
    *,
    rag_info: Optional[Dict[str, Any]] = None,
) -> None:
    st.subheader("Fail-soft ì‘ë‹µ")
    if not payload:
        st.info("ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    segments = payload.get("segments") or []
    if not segments:
        st.info("ì‘ë‹µì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    rag_error = (rag_info or {}).get("error") if rag_info else None

    for segment in segments:
        cols = st.columns([12, 1])
        with cols[0]:
            st.markdown(f"- {segment.get('text')}")
        with cols[1]:
            evidence_chunk = segment.get("evidence")
            evidence_meta = segment.get("evidence_meta")
            source = segment.get("source")
            if evidence_chunk:
                _render_evidence_badge(evidence_chunk, evidence_meta)
            elif source == "rag":
                rag_enabled = bool((rag_info or {}).get("enabled"))
                if rag_enabled:
                    _render_evidence_badge(None, None, tooltip="ê´€ë ¨ ê·¼ê±° ì—†ìŒ")
                elif rag_error:
                    _render_evidence_badge(None, None, tooltip=f"RAG ì˜¤ë¥˜: {rag_error}")
                else:
                    _render_evidence_badge(None, None, disabled=True, tooltip="RAG ë¹„í™œì„±í™”")

    caveats = payload.get("caveats") or []
    if caveats:
        unique_caveats = []
        for item in caveats:
            if item and item not in unique_caveats:
                unique_caveats.append(item)
        if unique_caveats:
            st.caption("ì£¼ì˜ ì‚¬í•­")
            for item in unique_caveats:
                st.markdown(f"- {item}")

    if rag_error and all("RAG ì˜¤ë¥˜" not in item for item in caveats):
        st.error(f"RAG ì˜¤ë¥˜: {rag_error}")

    _render_sources_footer(payload.get("used_data") or {})

def _render_evidence_badge(
    chunk: dict | None,
    evidence_meta: dict | None,
    *,
    disabled: bool = False,
    tooltip: str | None = None,
) -> None:
    if disabled:
        label = "ğŸ“ (OFF)"
        if tooltip:
            label += f" â€” {tooltip}"
        st.caption(label)
        return

    if not chunk:
        if tooltip:
            st.caption(f"ğŸ“ {tooltip}")
        else:
            st.write("")
        return

    popover_fn = getattr(st, "popover", None)
    score = chunk.get("score")
    score_text = f"{float(score):.3f}" if score is not None else "â€”"
    doc_id = chunk.get("doc_id") or "â€”"
    chunk_id = chunk.get("chunk_id") or "â€”"
    title = evidence_meta.get("title") if isinstance(evidence_meta, dict) else None
    uri = evidence_meta.get("uri") if isinstance(evidence_meta, dict) else None

    def _short_label(value: str) -> str:
        text = str(value or "")
        if len(text) <= 8:
            return text
        return text[:5] + "â€¦"

    display_token = chunk.get("chunk_id") or chunk.get("doc_id") or "ê·¼ê±°"
    badge_label = f"ğŸ“ {_short_label(display_token)}Â·{score_text}"

    body_lines = [f"**ë¬¸ì„œ ì œëª©:** {title or doc_id}"]
    body_lines.append(f"**ë¬¸ì„œ ID:** {doc_id}")
    body_lines.append(f"**Chunk ID:** {chunk_id}")
    body_lines.append(f"**ìœ ì‚¬ë„:** {score_text}")
    text = chunk.get("text") or "â€”"
    body_lines.append("\n**ë‚´ìš© ë°œì·Œ**\n")
    body_lines.append(text)
    if uri:
        body_lines.append(f"\n[ì›ë³¸ ì—´ê¸°]({uri})")

    if callable(popover_fn):
        with popover_fn(badge_label):
            for line in body_lines:
                st.markdown(line)
    else:  # pragma: no cover - fallback for older Streamlit
        with st.expander(badge_label, expanded=False):
            for line in body_lines:
                st.markdown(line)


def _mask_name(raw: str) -> str:
    if not raw:
        return "â€”"
    name = str(raw)
    if "*" in name:
        return name
    trimmed = name.strip()
    if len(trimmed) <= 1:
        return trimmed or "â€”"
    if len(trimmed) == 2:
        return trimmed[0] + "*"
    return trimmed[:2] + ("*" * max(4, len(trimmed) - 2))


def _extract_merchant_name(agent1_json: dict) -> str:
    context = (agent1_json or {}).get("context", {})
    keys = [
        "merchant_masked_name",
        "masked_name",
        "merchant_name_masked",
        "merchant_name",
        "store_name"
    ]
    for key in keys:
        val = context.get(key)
        if val:
            return _mask_name(val)
    return "â€”"


def _format_percent(value) -> str:
    if value is None:
        return "â€”"
    try:
        num = float(value)
    except (TypeError, ValueError):
        return "â€”"
    if num < 0 or num > 100:
        return "â€”"
    return f"{num:.1f}%"


def _collect_major_customers(agent1_json: dict) -> str:
    buckets = merge_age_buckets(agent1_json or {})
    if not buckets:
        return "â€”"
    segments: list[str] = []
    for bucket in buckets[:3]:
        label = bucket.get("label") or bucket.get("key") or "â€”"
        value = bucket.get("value")
        if isinstance(value, (int, float)):
            segments.append(f"{label} {value:.1f}%")
        else:
            segments.append(f"{label} â€”")
    return ", ".join(segments) if segments else "â€”"


def _format_customer_mix(detail: dict | None) -> str:
    if not detail or not isinstance(detail, dict):
        return "â€”"
    ordered_labels = ["ìœ ë™", "ê±°ì£¼", "ì§ì¥"]
    parts = []
    for label in ordered_labels:
        value = detail.get(label)
        if value is not None:
            percent = _format_percent(value)
            if percent != "â€”":
                parts.append(f"{label} {percent}")
    for label, value in detail.items():
        if label in ordered_labels:
            continue
        if value is None:
            continue
        percent = _format_percent(value)
        if percent != "â€”":
            parts.append(f"{label} {percent}")
    return ", ".join(parts[:3]) if parts else "â€”"


def _collect_overview_row(agent1_json: dict) -> tuple[pd.DataFrame, dict]:
    context = (agent1_json or {}).get("context", {})
    parsed = context.get("parsed", {})
    merchant = context.get("merchant", {})
    industry_candidate = merchant.get("category") or parsed.get("merchant_industry_label") or parsed.get("industry")
    industry_labels = {
        "cafe": "ì¹´í˜",
        "restaurant": "ìŒì‹ì ",
        "retail": "ì†Œë§¤"
    }
    industry = industry_labels.get(industry_candidate, industry_candidate or "â€”")
    addr = merchant.get("address") or context.get("address_masked") or context.get("address") or context.get("addr_base")
    if isinstance(addr, (list, tuple)):
        addr = " / ".join([str(v) for v in addr if v])
    address = addr if addr else "â€”"

    debug_snapshot = _get_debug_snapshot(agent1_json)
    kpis = (agent1_json or {}).get("kpis", {})
    new_rate = debug_snapshot.get("new_pct", kpis.get("new_rate_avg"))
    revisit_rate = debug_snapshot.get("revisit_pct", kpis.get("revisit_rate_avg"))
    new_text = _format_percent(new_rate)
    revisit_text = _format_percent(revisit_rate)
    if new_text == "â€”" and revisit_text == "â€”":
        new_revisit = "â€”"
    else:
        new_revisit = f"ì‹ ê·œ {new_text} / ì¬ë°©ë¬¸ {revisit_text}"

    customer_mix_detail = debug_snapshot.get("customer_mix_detail") or kpis.get("customer_mix_detail")
    customer_type = _format_customer_mix(customer_mix_detail)
    spend_band = (
        debug_snapshot.get("avg_ticket_band_label")
        or kpis.get("avg_ticket_band_label")
        or context.get("avg_ticket_band")
        or "â€”"
    )
    if isinstance(spend_band, str):
        spend_band = spend_band.strip()
        spend_band = re.sub(r"(ìƒìœ„)(\d)", r"\1 \2", spend_band)
    elif spend_band is None:
        spend_band = "â€”"

    data = {
        "ì—…ì¢…": industry,
        "ì£¼ì†Œ": address,
        "ì£¼ìš” ê³ ê°ì¸µ": _collect_major_customers(agent1_json),
        "ê³ ê° ìœ í˜•": customer_type if customer_type else "â€”",
        "ì‹ ê·œ/ì¬ë°©ë¬¸": new_revisit,
        "ê°ë‹¨ê°€ êµ¬ê°„": spend_band if spend_band else "â€”"
    }
    return pd.DataFrame([data]), data


def _build_diagnosis(agent1_json: dict) -> List[str]:
    try:
        return three_line_diagnosis(agent1_json or {})
    except Exception:
        return ["ìš”ì•½ ìƒì„± ì˜¤ë¥˜", "ë°ì´í„° í™•ì¸ í•„ìš”", "â€”"]


def _build_goal_lines(agent1_json: dict) -> tuple[str, list[str]]:
    period = (agent1_json or {}).get("period", {})
    months = period.get("months")
    weeks_requested = period.get("weeks_requested")
    if weeks_requested:
        try:
            weeks_val = int(weeks_requested)
        except (TypeError, ValueError):
            weeks_val = None
        if weeks_val and months:
            period_text = f"í–¥í›„ {weeks_val}ì£¼ (ì•½ {months}ê°œì›”)"
        elif weeks_val:
            period_text = f"í–¥í›„ {weeks_val}ì£¼"
        else:
            period_text = "ê¸°ê°„ ì •ë³´ â€”"
    elif months:
        period_text = f"ìµœê·¼ {months}ê°œì›”"
    else:
        period_text = "ê¸°ê°„ ì •ë³´ â€”"

    debug_snapshot = _get_debug_snapshot(agent1_json)
    kpis = (agent1_json or {}).get("kpis", {})
    mapping = [
        ("revisit_rate_avg", "ì¬ë°©ë¬¸ìœ¨"),
        ("new_rate_avg", "ì‹ ê·œ ê³ ê° ë¹„ì¤‘"),
        ("youth_share_avg", "ì²­ë…„ ê³ ê° ë¹„ì¤‘")
    ]
    lines = []
    for key, label in mapping:
        sanitized_key = {
            "revisit_rate_avg": "revisit_pct",
            "new_rate_avg": "new_pct",
            "youth_share_avg": "youth_pct",
        }.get(key)
        value = debug_snapshot.get(sanitized_key, kpis.get(key))
        if value is not None:
            lines.append(f"{label}: í˜„í™© {_format_percent(value)} â†’ ëª©í‘œ êµ¬ê°„ â€”")
    if not lines:
        lines.append("KPI ëª©í‘œ êµ¬ê°„ â€”")
    return period_text, lines[:3]


def _format_list(values) -> str:
    if not values:
        return "â€”"
    if isinstance(values, (list, tuple)):
        items = [str(v) for v in values if v]
        return " Â· ".join(items) if items else "â€”"
    return str(values)


def render_summary_view(
    agent1_json: dict,
    agent2_json: dict,
    overview_df: pd.DataFrame | None = None,
    table_dict: dict | None = None,
    retrieval_payload: dict | None = None,
) -> None:
    merchant_title = _extract_merchant_name(agent1_json)
    st.header(f"ğŸ“Š {merchant_title} ê°€ë§¹ì  ë°©ë¬¸ ê³ ê° í˜„í™© ë¶„ì„")

    context = (agent1_json or {}).get("context", {})
    if context and not context.get("merchant"):
        st.warning("ì§ˆë¬¸ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ê°€ë§¹ì ì„ ì°¾ì§€ ëª»í•´ í‘œë³¸ ì „ì²´ ìš”ì•½ì„ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.")

    debug_info = _get_debug_section(agent1_json)
    if overview_df is None or table_dict is None:
        render_info = debug_info.get("render") if isinstance(debug_info, dict) else None
        if isinstance(render_info, dict) and isinstance(render_info.get("table_dict"), dict):
            table_dict = render_info.get("table_dict")
            overview_df = pd.DataFrame([table_dict])
        else:
            overview_df, table_dict = _collect_overview_row(agent1_json)
            if isinstance(debug_info, dict):
                debug_info.setdefault("render", {})["table_dict"] = table_dict
    if overview_df is None:
        if table_dict:
            overview_df = pd.DataFrame([table_dict])
        else:
            overview_df = pd.DataFrame()
    is_public_mode = APP_MODE == "public"
    try:
        print("ğŸ“Š overview_table:", json.dumps(overview_df.to_dict(orient="records"), ensure_ascii=False))
    except Exception:
        pass

    if is_public_mode:
        st.subheader("í˜„í™© ìš”ì•½")
        if table_dict:
            summary_df = pd.DataFrame(list(table_dict.items()), columns=["í•­ëª©", "ê°’"]).head(3)
            st.table(summary_df)
        else:
            st.info("ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.subheader("í˜„í™© í‘œ")
        st.table(overview_df)

    st.subheader("í•œ ì¤„ ì§„ë‹¨")
    diagnosis_lines = _build_diagnosis(agent1_json)
    if not diagnosis_lines:
        diagnosis_lines = ["ìš”ì•½ ì •ë³´ ì—†ìŒ", "â€”", "â€”"]
    if retrieval_payload and retrieval_payload.get("chunks"):
        best_chunk = retrieval_payload["chunks"][0]
        evidence_meta = None
        for item in retrieval_payload.get("evidence", []):
            if item.get("doc_id") == best_chunk.get("doc_id") and item.get("chunk_id") == best_chunk.get("chunk_id"):
                evidence_meta = item
                break
        cols = st.columns([12, 1])
        with cols[0]:
            for line in diagnosis_lines:
                st.markdown(f"- {line}")
        with cols[1]:
            _render_evidence_badge(best_chunk, evidence_meta)
    else:
        for line in diagnosis_lines:
            st.markdown(f"- {line}")

    if not is_public_mode:
        period_text, goal_lines = _build_goal_lines(agent1_json)
        st.subheader("ëª©í‘œ")
        st.markdown(f"- ê¸°ê°„ ê°€ì •: {period_text}")
        for line in goal_lines:
            st.markdown(f"- {line}")

    agent2_payload = agent2_json or {}
    answers = agent2_payload.get("answers") or agent2_payload.get("recommendations") or []
    if not isinstance(answers, list):
        answers = []

    st.subheader("ì•„ì´ë””ì–´ ì œì•ˆ")
    if not answers:
        st.info("ì•„ì´ë””ì–´ ì œì•ˆì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    for idx, answer in enumerate(answers[:4], start=1):
        with st.container():
            st.markdown(f"**{idx}. {answer.get('idea_title', 'â€”')}**")
            st.markdown(f"- ëŒ€ìƒ: {answer.get('audience', 'â€”')}")
            st.markdown(f"- ì±„ë„: {_format_list(answer.get('channels'))}")
            st.markdown(f"- ì‹¤í–‰: {_format_list(answer.get('execution'))}")
            st.markdown(f"- ì¹´í”¼ ìƒ˜í”Œ: {_format_list(answer.get('copy_samples'))}")
            st.markdown(f"- ì¸¡ì •: {_format_list(answer.get('measurement'))}")

            evidence_items = answer.get("evidence") or []
            if evidence_items:
                st.markdown("**ê·¼ê±°**")
                for entry in evidence_items:
                    line = _format_evidence_line(entry)
                    cols = st.columns([12, 1])
                    with cols[0]:
                        st.markdown(line)
                    with cols[1]:
                        source = str(entry.get("source") or "").upper()
                        if source == "RAG":
                            chunk, meta = _match_evidence_chunk(entry, retrieval_payload)
                            if chunk:
                                _render_evidence_badge(chunk, meta)
                            else:
                                _render_evidence_badge(
                                    None,
                                    None,
                                    disabled=True,
                                    tooltip="RAG ê·¼ê±° ë§¤ì¹­ ì‹¤íŒ¨",
                                )
                        elif source in {"STRUCTURED", "WEATHER", "EXTERNAL"}:
                            _render_evidence_badge(
                                None,
                                None,
                                disabled=True,
                                tooltip=f"{source} ê·¼ê±°",
                            )
                        else:
                            tooltip = "ê·¼ê±° ì—†ìŒ" if source in {"NONE", ""} else source
                            _render_evidence_badge(None, None, disabled=True, tooltip=tooltip)
            else:
                st.markdown("**ê·¼ê±°**")
                cols = st.columns([12, 1])
                with cols[0]:
                    st.markdown("- ê·¼ê±° ì—†ìŒ")
                with cols[1]:
                    _render_evidence_badge(None, None, disabled=True, tooltip="ê·¼ê±° ì—†ìŒ")

    if not is_public_mode:
        limits = (agent1_json or {}).get("limits", [])
        st.subheader("í•œê³„/ë°ì´í„° ë³´ê°•")
        st.markdown("**í˜„ì¬ í•œê³„**")
        if limits:
            for item in limits[:5]:
                st.markdown(f"- {item}")
        else:
            st.markdown("- í•œê³„ ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        improvement_suggestions = []
        for item in limits:
            text = str(item)
            if "ë‚ ì”¨" in text:
                improvement_suggestions.append("ë‚ ì”¨ ë°ì´í„° ì—°ê³„ë¥¼ í†µí•´ ìš°ì²œ ê°€ì„¤ì„ ê²€ì¦í•©ë‹ˆë‹¤.")
            elif "í‘œë³¸" in text or "ë°ì´í„°" in text:
                improvement_suggestions.append("ëˆ„ë½ êµ¬ê°„ì„ ì ê²€í•´ í‘œë³¸ì„ ë³´ê°•í•©ë‹ˆë‹¤.")
        if not improvement_suggestions:
            improvement_suggestions.append("ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸ì—ì„œ ê²°í•© ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¬ì ê²€í•©ë‹ˆë‹¤.")

        st.markdown("**ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸ ë³´ê°• ê³„íš**")
        for suggestion in improvement_suggestions[:3]:
            st.markdown(f"- {suggestion}")

        if retrieval_payload and retrieval_payload.get("chunks"):
            st.subheader("ì„ë² ë””ë“œ ê·¼ê±°")
            for idx, chunk in enumerate(retrieval_payload.get("chunks", [])[:5], start=1):
                meta = None
                for item in retrieval_payload.get("evidence", []):
                    if item.get("doc_id") == chunk.get("doc_id") and item.get("chunk_id") == chunk.get("chunk_id"):
                        meta = item
                        break
                cols = st.columns([12, 1])
                with cols[0]:
                    preview = str(chunk.get("text") or "â€”")
                    preview = preview.strip()
                    if len(preview) > 160:
                        preview = preview[:160].rstrip() + "â€¦"
                    st.markdown(f"{idx}. {preview}")
                with cols[1]:
                    _render_evidence_badge(chunk, meta)

# ===== ê²½ë¡œ & í‚¤ =====
DATA_DIR = Path("data")
SHINHAN_DIR = DATA_DIR / "shinhan"
EXTERNAL_DIR = DATA_DIR / "external"

API_KEY = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY", "")
if not API_KEY:
    st.warning("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì•± ì„¤ì •ì˜ App secretsì— ë“±ë¡í•˜ì„¸ìš”)")

# ===== ì‚¬ì´ë“œë°”: ë°ì´í„° ìƒíƒœ =====
st.sidebar.header("ë°ì´í„° ìƒíƒœ")
st.sidebar.write(f"ğŸ“ SHINHAN_DIR ì¡´ì¬: {SHINHAN_DIR.exists()}")
st.sidebar.write(f"ğŸ“ EXTERNAL_DIR ì¡´ì¬: {EXTERNAL_DIR.exists()}")

data_flags = st.session_state.get("_data_flags", {})
st.sidebar.header("Data Sources")
mode_options = ["public", "debug"]
mode_labels = {"public": "Public", "debug": "Debug"}
mode_index = mode_options.index(APP_MODE) if APP_MODE in mode_options else 0
selected_mode = st.sidebar.selectbox(
    "App Mode",
    mode_options,
    index=mode_index,
    format_func=lambda val: mode_labels.get(val, val),
)
if selected_mode != APP_MODE:
    st.session_state["_app_mode"] = selected_mode
    if selected_mode != "debug":
        st.session_state["show_debug_checkbox"] = False
    st.experimental_rerun()

data_flags["use_weather"] = st.sidebar.toggle(
    "Use Weather Data",
    value=bool(data_flags.get("use_weather", False)),
)
data_flags["use_external"] = st.sidebar.toggle(
    "Use External APIs",
    value=bool(data_flags.get("use_external", False)),
)

rag_root_exists = RAG_ROOT_PATH.exists()
if rag_root_exists:
    st.sidebar.caption(f"RAG Root: {RAG_ROOT_PATH}")
else:
    st.sidebar.info(f"RAG_ROOT ê²½ë¡œ({RAG_ROOT_PATH})ê°€ ì—†ì–´ RAGë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if RAG_CATALOG_ERROR:
    st.sidebar.warning(RAG_CATALOG_ERROR)

rag_toggle_disabled = (
    RETRIEVAL_TOOL is None
    or RETRIEVAL_INIT_ERROR is not None
    or not rag_root_exists
    or RAG_CATALOG_ERROR is not None
)
if rag_toggle_disabled:
    data_flags["use_rag"] = False
    st.sidebar.toggle(
        "Use RAG (Embedded Docs)",
        value=False,
        disabled=True,
        help="RetrievalToolì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.",
    )
    data_flags["rag_selected_ids"] = []
else:
    data_flags["use_rag"] = st.sidebar.toggle(
        "Use RAG (Embedded Docs)",
        value=bool(data_flags.get("use_rag", True)),
    )

rag_threshold_default = float(data_flags.get("rag_threshold", 0.35))
data_flags["rag_threshold"] = float(
    st.sidebar.slider(
        "RAG Threshold",
        min_value=0.2,
        max_value=0.6,
        value=rag_threshold_default,
        step=0.05,
        disabled=rag_toggle_disabled,
    )
)
data_flags["rag_top_k"] = int(
    st.sidebar.slider(
        "RAG top_k",
        min_value=3,
        max_value=10,
        value=int(data_flags.get("rag_top_k", 5)),
        step=1,
        disabled=rag_toggle_disabled,
    )
)
rag_modes = ["auto", "always", "off"]
rag_mode_value = data_flags.get("rag_mode", "auto")
if rag_mode_value not in rag_modes:
    rag_mode_value = "auto"
data_flags["rag_mode"] = st.sidebar.selectbox(
    "RAG Mode",
    options=rag_modes,
    index=rag_modes.index(rag_mode_value),
    disabled=rag_toggle_disabled,
)

if not rag_toggle_disabled and data_flags.get("use_rag"):
    current_filter = data_flags.get("rag_filter", "")
    current_filter = st.sidebar.text_input(
        "RAG Search Filter (optional)",
        value=current_filter,
        placeholder="ë¬¸ì„œëª…, íƒœê·¸, ID ê²€ìƒ‰",
    )
    data_flags["rag_filter"] = current_filter

    def _matches_filter(record: Dict[str, Any], query: str) -> bool:
        if not query:
            return True
        haystack_parts = [
            str(record.get("title") or ""),
            str(record.get("document_id") or ""),
        ]
        tags = record.get("tags") or []
        haystack_parts.extend(str(tag) for tag in tags)
        haystack = " ".join(haystack_parts).lower()
        return query.lower() in haystack

    filtered_catalog = [
        item for item in RAG_CATALOG if _matches_filter(item, current_filter.strip())
    ]

    if not filtered_catalog:
        st.sidebar.info("í•„í„°ì™€ ì¼ì¹˜í•˜ëŠ” ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ë¹„ì›Œì£¼ì„¸ìš”.")

    label_map = {
        f"{item['title']} ({item['document_id']})": item["document_id"]
        for item in filtered_catalog
    }
    options = list(label_map.keys())

    previous_selection = data_flags.get("rag_selected_ids") or []
    default_labels = [label for label, doc_id in label_map.items() if doc_id in previous_selection]
    if not default_labels and not previous_selection and len(options) <= 20:
        default_labels = options

    selected_labels = st.sidebar.multiselect(
        "Select RAG Documents",
        options,
        default=default_labels,
    )
    selected_ids = [label_map[label] for label in selected_labels]
    data_flags["rag_selected_ids"] = selected_ids

    if data_flags.get("use_rag") and not selected_ids:
        st.sidebar.info("ì„ íƒëœ RAG ë¬¸ì„œê°€ ì—†ì–´ ì´ë²ˆ ì‹¤í–‰ì—ì„œëŠ” RAGë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
elif not rag_toggle_disabled:
    # Toggleê°€ êº¼ì ¸ ìˆìœ¼ë©´ ê¸°ì¡´ ì„ íƒì„ ìœ ì§€í•˜ë˜ í•„í„° ì…ë ¥ë§Œ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    data_flags.setdefault("rag_selected_ids", data_flags.get("rag_selected_ids", []))

st.session_state["_data_flags"] = data_flags

# ===== íƒ­ êµ¬ì„± =====
analysis_tab, sources_tab = st.tabs(["ğŸ“ˆ ë¶„ì„", "ğŸ“š Embedded Sources"])

with analysis_tab:
    default_q = "ì„±ë™êµ¬ {ê³ í–¥***} ê¸°ì¤€ìœ¼ë¡œ, ì¬ë°©ë¬¸ìœ¨ 4ì£¼ í”Œëœ ì‘ì„±í•´ì¤˜."
    question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", value=default_q)
    st.caption("ìƒí˜¸ëŠ” ë°˜ë“œì‹œ {}ë¡œ ê°ì‹¸ ì£¼ì„¸ìš”. ì˜ˆ) ì„±ë™êµ¬ {ë™ëŒ€******}")

    run_analysis = st.button("ë¶„ì„ ì‹¤í–‰", type="primary")
    if run_analysis:
        from bigcon_2agent_mvp_v3 import (
            agent1_pipeline,
            build_agent2_prompt,
            call_gemini_agent2,
            AGENT2_PROMPT_TRACE,
            AGENT2_RESPONSE_TRACE,
            infer_question_type,
        )

        with st.spinner("Agent-1: ë°ì´í„° ì§‘ê³„/ìš”ì•½ ì¤‘..."):
            try:
                a1 = agent1_pipeline(question, SHINHAN_DIR, EXTERNAL_DIR)
                try:
                    overview_df, table_dict = _collect_overview_row(a1)
                except Exception:
                    overview_df, table_dict = pd.DataFrame(), {}
                if isinstance(a1, dict):
                    dbg = _get_debug_section(a1)
                    dbg.setdefault('render', {})['table_dict'] = table_dict
                    a1['debug'] = dbg
                st.session_state['_latest_overview'] = (overview_df, table_dict)
                st.session_state['_latest_agent1'] = a1
                st.session_state['_latest_question'] = question
                st.success("Agent-1 JSON ìƒì„± ì™„ë£Œ")
            except Exception:
                st.error("Agent-1 ì‹¤í–‰ ì˜¤ë¥˜")
                st.code(traceback.format_exc())
                st.stop()

        flags_snapshot = st.session_state.get("_data_flags", {}).copy()
        rag_info_for_prompt = _compute_rag_info(question, flags_snapshot)
        rag_prompt_context = _prepare_rag_prompt_context(rag_info_for_prompt)
        st.session_state['_latest_rag_info'] = rag_info_for_prompt
        question_type = infer_question_type(question)
        st.session_state['_latest_question_type'] = question_type
        st.session_state['_latest_rag_prompt_context'] = rag_prompt_context

        with st.spinner("Agent-2: ì¹´ë“œ ìƒì„± ì¤‘..."):
            try:
                os.environ["GEMINI_API_KEY"] = API_KEY
                prompt_text = build_agent2_prompt(
                    a1,
                    question_text=question,
                    question_type=question_type,
                    rag_context=rag_prompt_context,
                )
                if isinstance(AGENT2_PROMPT_TRACE, dict):
                    st.session_state["_latest_prompt_trace"] = dict(AGENT2_PROMPT_TRACE)
                else:
                    st.session_state["_latest_prompt_trace"] = {}
                result = call_gemini_agent2(
                    prompt_text,
                    question_type=question_type,
                    agent1_json=a1,
                )
                st.success("Agent-2 ì¹´ë“œ ìƒì„± ì™„ë£Œ")
                st.session_state['_latest_agent2'] = result
                if isinstance(AGENT2_RESPONSE_TRACE, dict):
                    st.session_state['_latest_response_trace'] = dict(AGENT2_RESPONSE_TRACE)
                else:
                    st.session_state['_latest_response_trace'] = {}
            except Exception:
                st.error("Agent-2 ì‹¤í–‰ ì˜¤ë¥˜")
                st.code(traceback.format_exc())
                st.stop()

        _render_main_views(question, a1, result, rag_info_override=rag_info_for_prompt)

    elif st.session_state.get('_latest_agent1') and st.session_state.get('_latest_agent2'):
        latest_agent1 = st.session_state.get('_latest_agent1')
        latest_agent2 = st.session_state.get('_latest_agent2')
        question_snapshot = st.session_state.get('_latest_question', question)
        _render_main_views(question_snapshot, latest_agent1, latest_agent2)

    latest_agent2 = st.session_state.get('_latest_agent2')
    if isinstance(latest_agent2, dict):
        with st.expander("ğŸ§¾ Agent-2 ì¶œë ¥(JSON) ë³´ê¸°", expanded=False):
            st.json(latest_agent2)
    latest_retrieval = st.session_state.get('_latest_retrieval')
    if latest_retrieval:
        with st.expander("ğŸ“ Retrieval Evidence (JSON)", expanded=False):
            st.json(latest_retrieval)
    latest_agent1 = st.session_state.get('_latest_agent1')
    if isinstance(latest_agent1, dict):
        with st.expander("ğŸ” Agent-1 ì¶œë ¥(JSON) ë³´ê¸°", expanded=False):
            st.json(latest_agent1)

    rag_flags = st.session_state.get("_data_flags", {})
    if RETRIEVAL_TOOL is not None and RETRIEVAL_INIT_ERROR is None:
        col_lo, col_hi = st.columns(2)
        if col_lo.button("ì„ê³„ê°’ ë‚®ì¶”ê¸° (-0.05)"):
            new_threshold = max(0.2, float(rag_flags.get("rag_threshold", 0.35)) - 0.05)
            st.session_state["_data_flags"]["rag_threshold"] = round(new_threshold, 2)
            st.experimental_rerun()
        if col_hi.button("ì„ê³„ê°’ ë†’ì´ê¸° (+0.05)"):
            new_threshold = min(0.6, float(rag_flags.get("rag_threshold", 0.35)) + 0.05)
            st.session_state["_data_flags"]["rag_threshold"] = round(new_threshold, 2)
            st.experimental_rerun()

    if show_debug:
        latest_agent1 = st.session_state.get('_latest_agent1')
        with st.expander("ğŸ” ë””ë²„ê·¸ ìƒì„¸", expanded=True):
            render_debug_view(latest_agent1, show_raw=DEBUG_SHOW_RAW)

    if not st.session_state.get("_intro_shown"):
        st.info("âœ… ì—…ë¡œë“œ ì„±ê³µ! ì´ì œ ì§ˆë¬¸ ì…ë ¥ í›„ [ë¶„ì„ ì‹¤í–‰]ì„ ëˆŒëŸ¬ ì¹´ë“œ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
        st.session_state["_intro_shown"] = True

with sources_tab:
    st.subheader("ì„ë² ë””ë“œ ì†ŒìŠ¤ ì¹´íƒˆë¡œê·¸")
    st.caption(f"RAG Root: {RAG_ROOT_PATH}")
    if RETRIEVAL_INIT_ERROR:
        st.error(f"RetrievalTool ì´ˆê¸°í™” ì‹¤íŒ¨: {RETRIEVAL_INIT_ERROR}")
    elif RETRIEVAL_TOOL is None:
        st.info("RetrievalToolì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    elif not RAG_ROOT_PATH.exists():
        st.info("data/rag ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. corpus/ì™€ indices/ë¥¼ êµ¬ì„±í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    elif RAG_CATALOG_ERROR:
        st.warning(RAG_CATALOG_ERROR)
    else:
        catalog_df = pd.DataFrame(RAG_CATALOG)
        if catalog_df.empty:
            st.info("ë“±ë¡ëœ ì„ë² ë””ë“œ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. data/rag/indices í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            display_columns = [
                "title",
                "document_id",
                "num_chunks",
                "embedding_model",
                "created_at",
                "origin_path",
            ]
            optional_cols = [col for col in ["tags", "year"] if col in catalog_df.columns]
            st.dataframe(
                catalog_df[display_columns + optional_cols],
                use_container_width=True,
            )
            doc_ids = catalog_df["document_id"].tolist()
            selected_doc = st.selectbox("ë¯¸ë¦¬ë³´ê¸° ë¬¸ì„œ", doc_ids, index=0 if doc_ids else None)
            if selected_doc:
                preview_chunks = RETRIEVAL_TOOL.preview_chunks(selected_doc)
                manifest_row = catalog_df[catalog_df["document_id"] == selected_doc].iloc[0]
                st.markdown(f"**ë¬¸ì„œ ì œëª©:** {manifest_row['title']}")
                origin_path = manifest_row.get("origin_path")
                if origin_path:
                    st.markdown(f"[ì›ë³¸ ì—´ê¸°]({origin_path})")
                tags = manifest_row.get("tags") or []
                if tags:
                    st.caption("íƒœê·¸: " + ", ".join(str(tag) for tag in tags))
                if not preview_chunks:
                    st.info("í”„ë¦¬ë·° ê°€ëŠ¥í•œ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    for chunk in preview_chunks:
                        with st.expander(f"Chunk {chunk.get('chunk_id')}"):
                            st.write(chunk.get("text") or "â€”")
